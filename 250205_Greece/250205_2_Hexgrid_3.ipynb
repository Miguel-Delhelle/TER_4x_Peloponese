{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Hexagonal grid(hexgrids) are an useful tool when one is performing spatial analysis in GIS. It is opposed to the ubiquitous square-patterned type of data (Raster, netCDF, etc.), which is more straightforward as the data can be rendered within an image format.\n",
    "\n",
    "Python is a relatively new tool, allowing the GIS analyst to leverage the power of Python's numerous libraries. These opensource libraries provide numerous tools for scientific calculation, such as statistical [Scikit learn] and spatial analysis library [PySAL](http://pysal.org/pysal/).\n",
    "As I aim at using the [Tobler](https://pysal.org/notebooks/model/tobler/intro.html) package, which is part of the [PySAL](http://pysal.org/pysal/) library, I would favor doing any calculations of [spatial interpolation](https://docs.qgis.org/2.18/en/docs/gentle_gis_introduction/spatial_analysis_interpolation.html) in a hexgrid pattern. \n",
    "\n",
    "Hexgrid pattern offers indeed the same amount of contact length for each of its neighbors, which is not the case with your default pixels. It is then up to the operator to pick a law that is mitigating the influence of corner pixels(nearest neighbor, bilinear interpolation, trilinear interpolation) on the calculation. Since a hexgrid cell is contacting its neighbouring cells by the same amount, calculation results are less tricky to make sense of. Also, there won't be any error generated by decreasing the hexgrid mesh resolution, lowering its cell count in general.\n",
    "Furthermore, I expect hexgrid to be more robust dealilng with datasources of different resolution for interpolation calculations.\n",
    "\n",
    "While the [h3fy function](https://pysal.org/tobler/notebooks/census_to_hexgrid.html) from Tobler's package is providing a quick way to creating a hex grid atop of geographical data, I achieved the same functionnality using GeoPandas and [Shapely](https://shapely.readthedocs.io/en/stable/index.html)'s [Voronoi Polygons](https://shapely.readthedocs.io/en/stable/reference/shapely.voronoi_polygons.html) method.\n",
    "\n",
    "This work is meant to find out pyhton syntax useful to gather data from a PostGIS Database to perform treatment using Python's aforementionned libraries.\n",
    "\n",
    "Any feedback is appreciated.\n",
    "\n",
    "\n",
    "# Hexgrid on GIS data\n",
    "\n",
    "## Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import shapely as shp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're supplying the [database URL](https://docs.sqlalchemy.org/en/20/core/engines.html#database-urls) so wa can setup [SQL Alchemy](https://docs.sqlalchemy.org/en/20/index.html)'s engine. Here, we're using [BD_Topo®](https://geoservices.ign.fr/bdtopo) data from France's IGN®, which is copied on a localhost database for convenience. We could use [\"Département 34 - Hérault\"](https://geoservices.ign.fr/bdtopo#telechargementshpdept) in particular.\n",
    "We'll use later on France's official boundaries, with the [Admin Express](https://geoservices.ign.fr/adminexpress) dataset. But I've been importing a dataset from IGN's BD Topo Dataset, which is drawn after the former layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = gpd.read_file('periphereies/periphereies.shp')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Of hexgrids\n",
    "\n",
    "The *a* parameter is the distance separating the centroids of each hex cell. It's our resolution and it's set in the map's units (generally, meters). We're building our hex cells off of their centroid. Hence we are introducing the height *h* betwenn rows so that we'll eventually have an equiditant length between the points we're picking. $$h = \\sqrt{a^2 - (a/2)^2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 10000 # smaller value means a lot a cells in the end result !\n",
    "\n",
    "h = (a**2 - (a/2)**2)**(1/2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mesh constructing with points\n",
    "\n",
    "Let such a mesh happen within our considered area of interest. We'll define its *bounding box*. Our point mesh is drawn along the units of our Coordinate Reference System (**CRS**). \n",
    "First, we're calling GeoPanda's [total_bounds](https://geopandas.org/en/stable/docs/reference/api/geopandas.GeoSeries.total_bounds.html) function, and we're defining our min and max values accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areaofinterest = layer.total_bounds \n",
    "x_min, y_min, x_max, y_max = [areaofinterest[m] for m in range(4)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll implement two indexes, one referencing the position along the x axis, the other the position along the y axis. We'll later pick one out of two points of the mesh we're creating using these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meshpoints_x = []\n",
    "meshpoints_y = []\n",
    "id_x =[]\n",
    "id_y =[]\n",
    "y_shift = y_min\n",
    "idy = 0\n",
    "idx = 0\n",
    "while y_shift < y_max + (h/2):\n",
    "    x_shift = x_min - (3/2)*a\n",
    "    while x_shift < x_max + (a/2):\n",
    "        meshpoints_x.append(x_shift)\n",
    "        meshpoints_y.append(y_shift)\n",
    "        id_x.append(idx)\n",
    "        id_y.append(idy)\n",
    "        x_shift += a/2\n",
    "        idx += 1\n",
    "    idy += 1\n",
    "    idx = 0  # reset the counter along the X axis\n",
    "    y_shift += h\n",
    "mesh_df = pd.DataFrame(data={'idx':id_x, 'idy':id_y, 'big_X':meshpoints_x, 'big_Y':meshpoints_y})   # gathering the lists' values in a Panda's DataFrame\n",
    "mesh_df[\"geometry\"]  = mesh_df.apply(lambda row: shp.Point(row.big_X, row.big_Y), axis=1)           # geometry creation\n",
    "mesh_gdf = gpd.GeoDataFrame(mesh_df, geometry=mesh_df['geometry'], crs=layer.crs)                   # fitting the geometry creation along with associated data in a DataFrame\n",
    "# mesh_gdf  # TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST are my indexes behaving the way they're expected to\n",
    "fig, axes = plt.subplots(ncols=2, nrows=1, figsize=(10,3), facecolor=(0.16,0.16,0.16))\n",
    "[mesh_gdf.plot(ax=axes[i], column='idx') for i in range(0,2)]   # comprehension list\n",
    "[axes[i].set_title('idx')for i in range(0,2)]                   # comprehension list\n",
    "fig.suptitle('Index value repartition');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I expected idx values to continuously vary along the x axis, while remaining the same from row to row. Meanwhile, I expected idy to behave the other way around. Hence I'm satisfied with the results.\n",
    "\n",
    "Also, take a notice at the density of points in the GeoDataFrame.\n",
    "\n",
    "### Equidistant point mesh\n",
    "\n",
    "I'm picking point which idx index is even *and* idy index is even *as well as* (***or*** status) odd idx's **and** odd idy's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evens = mesh_gdf[(mesh_gdf['idy'] % 2 == 0)&(mesh_gdf['idx'] % 2 == 0)] # TEST\n",
    "oddsandevens = mesh_gdf[(mesh_gdf['idy'] % 2 == 0)&(mesh_gdf['idx'] % 2 == 0) | (mesh_gdf['idy'] % 2 == 1)&(mesh_gdf['idx'] % 2 == 1)].copy()\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, nrows=1, figsize=(10,3), facecolor=(0.16,0.16,0.16))\n",
    "[oddsandevens.plot(ax=axes[i], column='idx') for i in range(0,2)]\n",
    "[axes[i].set_title('idx') for i in range(0,2)]\n",
    "fig.suptitle('Index value repartition');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection of useful points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calclating the buffer\n",
    "buffer = layer.buffer(2*a).unary_union  # seems more optimized than buffer = layer.unary_union.buffer(2*a)\n",
    "layer_buffer = gpd.GeoDataFrame(geometry=[buffer], crs=layer.crs)\n",
    "# layer_buffer  # TEST\n",
    "\n",
    "# selection by localisation\n",
    "tri = gpd.sjoin(oddsandevens,layer_buffer, predicate='intersects', how='inner')\n",
    "tri.drop(columns='index_right', inplace=True)  #grooming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemap = layer.plot(figsize=(12,12), facecolor=(0.16,0.16,0.16))\n",
    "tri.plot(ax=basemap, color='aquamarine', edgecolor='lightseagreen', alpha=0.5);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voronois\n",
    "\n",
    "We're going from a geometrycollection to gettin a full-featured Pandas GeoDataFrame\n",
    "\n",
    "### Voronoi Creation\n",
    "\n",
    "Now is the time to use [Shapely](https://shapely.readthedocs.io/en/stable/index.html)'s [Voronoi Polygons](https://shapely.readthedocs.io/en/stable/reference/shapely.voronoi_polygons.html) method. Shapely is supplied when the GeoPandas package is installing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voronoi = shp.voronoi_polygons(tri.unary_union)\n",
    "voronoi # it is a geometrycollection at this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voronoi_df = gpd.GeoDataFrame(geometry=[voronoi])  # [voronoi] is a list\n",
    "voronoi_df[\"geometries\"] = voronoi_df.apply(lambda row: [g for g in row.geometry.geoms], axis=1)\n",
    "voronoi_df.plot();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the coordinate match our layer's CRS. But to this point, Shapely's Voronoi output is considered \"naive geometry\", though it is now encapsulated in a GeoDataFrame. We thus need to declare explicitly its refercence system. You'd also need to specify *inplace=True* so that the declaration is effectively implemented on the GeoDataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voronoi_df.drop(columns='geometries', inplace=True)\n",
    "voronoi_df.set_crs(layer.crs, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploding this multipolygon into as many polygons\n",
    "\n",
    "I want as many rows in my GeoDataFrame as there are cells in the geometry. [Explode() method](https://geopandas.org/en/stable/docs/reference/api/geopandas.GeoDataFrame.explode.html) is the cure.\n",
    "\n",
    "The method does preserve CRS declaration, hence no need to declare a CRS there. CRS mismatch can indeed cause issues with GeoPanda's [clipping method](https://geopandas.org/en/stable/docs/reference/api/geopandas.clip.html#geopandas.clip)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_df = voronoi_df.explode(index_parts=True)\n",
    "# exploded_df.plot()  # TEST"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trimming\n",
    "\n",
    "### Polygon Clipping\n",
    "\n",
    "If I kept cells that are on top of coastal area without [clipping](https://geopandas.org/en/stable/docs/reference/api/geopandas.clip.html#geopandas.clip) them to the shore line, I'd have erroneous numbers in my spatial interpolation since there would be no way to differentiate the \"NO DATA\" part ouf our study -missing or unreliable figures- with the \"NO DATA\" as data that is outside of the studied area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_clip = gpd.clip(gdf=exploded_df, mask=layer, keep_geom_type=False)\n",
    "hex_clip.head()   # TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemap = layer.plot(figsize=(12,12), facecolor=(0.16,0.16,0.16), zorder=1)\n",
    "# basemap = tri.plot(ax=basemap, facecolor='slategrey',alpha = 0.5, zorder=3)\n",
    "hex_clip.plot(ax=basemap, facecolor='none', ec='peru', zorder=2);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Un-buffered greece\n",
    "\n",
    "oddsandevens is our points'frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voronoi_andevens = shp.voronoi_polygons(oddsandevens.unary_union)\n",
    "# voronoi_andevens = shp.voronoi_polygons(oddsandevens.buffer(2*a).unary_union)\n",
    "\n",
    "voronoi_andevens  # it is a geometrycollection at this point\n",
    "voronoi_andevens_df = gpd.GeoDataFrame(geometry=[voronoi_andevens])  # [voronoi] is a list\n",
    "voronoi_andevens_df[\"geometries\"] = voronoi_andevens_df.apply(lambda row: [g for g in row.geometry.geoms], axis=1)\n",
    "voronoi_andevens_df.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voronoi_andevens_df.drop(columns='geometries', inplace=True)\n",
    "voronoi_andevens_df.set_crs(layer.crs, inplace=True)\n",
    "exploded_andevens_df = voronoi_andevens_df.explode(index_parts=True)\n",
    "exploded_andevens_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_clip.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clipping\n",
    "exploded_andevens_clip = gpd.clip(gdf=exploded_andevens_df, mask=layer.total_bounds, keep_geom_type=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_andevens_clip_df = gpd.GeoDataFrame(data=exploded_andevens_clip, crs=layer.crs)\n",
    "exploded_andevens_clip_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a bounding box geodataframe\n",
    "\n",
    "from a bit of help from the [boundary](https://geopandas.org/en/stable/docs/reference/api/geopandas.GeoSeries.boundary.html) geoseries, which in turn allows us to creating a [geodataframe](https://geopandas.org/en/stable/docs/reference/api/geopandas.GeoDataFrame.html). And we'll buffer that guy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_boundary = gpd.GeoSeries( Polygon([(x_min, y_max), (x_max, y_max) ,(x_max, y_min),(x_min, y_min)]))\n",
    "layer_boundary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_boundary_df =  gpd.GeoDataFrame({'geometry':layer_boundary}, crs=layer.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a bounding box geodataframe\n",
    "\n",
    "\n",
    "layer_bounds_df = gpd.GeoDataFrame(geometry=[layer.total_bounds], crs=layer.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection by localisation\n",
    "exploded_andevens_select = gpd.sjoin(exploded_andevens_clip_df, layer, predicate='intersects', how='inner')\n",
    "exploded_andevens_select.drop(columns='index_right', inplace=True)  #grooming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_andevens_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemap = layer.plot(figsize=(12,12), facecolor=(0.16,0.16,0.16), zorder=1)\n",
    "exploded_andevens_clip.plot(ax=basemap,facecolor='none', ec='cadetblue', zorder=3)\n",
    "exploded_andevens_select.plot(ax=basemap,facecolor='none', ec='rebeccapurple', zorder=4);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to Shapefile : make all of these guys a multipolygon\n",
    "\n",
    "Notice we make are reusing our *a* parameter to name our file. I'm replacing files with the same name. These combined conventions are allowing me to run th script over and over without flooding my database and keep different scaled data in my database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_clip['geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing to Shapefile\n",
    "hex_clip['geometry'].to_file(\"hex_clip_{}.shp\".format(a))\n",
    "# hex_clip['geometry'].to_file(\"hex_clip_10000.shp\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "\n",
    "J'ai téléchargé un [shapefile](https://geodata.gov.gr/en/dataset/periphereies-elladas/resource/7c80a2c1-93b7-4814-9fc4-245e775acaa6) des régions administratives du site [GEODATA.gov.gr](GEODATA.gov.gr). Projection 2100, que ne lit pas QGIS. J'ai vérifié le décalage avec la carte du monde livrée avec QGIS (si on tape WORLD dans les coordonnées)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Virutual_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
